{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7b7962-4844-41b1-9721-1b496faa4d44",
   "metadata": {},
   "source": [
    "# I Sentiment Orientation Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5203bd-1fe7-4e4d-a5d3-7b9dcce708dc",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Loading Data and Libraries](#loading-dependencies)\n",
    "2. [Loading the model](#model)\n",
    "3. [Check for Token Overflow in commentBody](#Preprocess-Tokenize-Overflow)\n",
    "4. [Sentiment analysis](#sentiment)\n",
    "5. [Saving Results](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20c25f-165d-4234-a889-dd2a49dd5303",
   "metadata": {},
   "source": [
    "## Loading Data and Libraries \n",
    "<a class=\"anchor\" id=\"loading-dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b35448-30a0-4929-916a-133f06a58a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "\n",
    "df_c = pd.read_parquet('Comments.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118d355-0a49-438e-a3bc-f8b8349008b3",
   "metadata": {},
   "source": [
    "## Loading the model \n",
    "<a class=\"anchor\" id=\"model\"></a>\n",
    "\n",
    "Using the pretrained model 'twitter-XLM-roBERTa-base for Sentiment Analysis' from the Cardiff NLP group at Cardiff University.  \n",
    "This Model was fine-tuned with 198M tweets in over thirty languages.  \n",
    "https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b6d8ea-b5cb-47ac-add6-628ff9ec1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#tokenizer.save_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2ed9c-a326-402f-b053-03a15b7de501",
   "metadata": {},
   "source": [
    "## Check for Token Overflow in commentBody\n",
    "<a class=\"anchor\" id=\"Preprocess-Tokenize-Overflow\"></a>\n",
    "\n",
    "1. **Preprocessing**  \n",
    "Replacing any mentioned usernames to ensure that mentions, which might carry sentiment connotations, do not influence the sentiment of the message.\n",
    "\n",
    "2. **Tokenizing**  \n",
    "Tokenize the comment text using the tokenizer included with the model.\n",
    "\n",
    "3. **Checking for Token Overflow**  \n",
    "Since the CardiffNLP/twitter-xlm-roberta-base-sentiment model allows a maximum token length of 512, a check of the token length is performed on a sample of the dataset (n=100,000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24324d8e-495e-4e52-9245-658a7223adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess comment sample: 100%|████████████████████████████████████████████| 100000/100000 [00:02<00:00, 36361.03it/s]\n",
      "Tokenize comment sample: 100%|███████████████████████████████████████████████| 100000/100000 [01:26<00:00, 1154.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of tokens: 95.42051\n",
      "Median number of tokens:  70.0\n",
      "Minimum number of tokens: 3\n",
      "Maximum number of tokens: 786\n",
      "Number of tokens > 512:   17\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocess the comment by replacing usernames, links and newline caracters.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Unporcessed comment Body.\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned comment Body\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \"\") \n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "    \n",
    "def tokenize_text(text): \n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=1024, padding=True).to('cuda')\n",
    "    return encoded_input\n",
    "\n",
    "def count_tokens(tokenized_input):\n",
    "    return tokenized_input['input_ids'].shape[1]  \n",
    "    \n",
    "\n",
    "tqdm.pandas(desc=\"Preprocess comment sample\")\n",
    "df_c = df_c[df_c['commentBody'].notna()].copy()\n",
    "df_s = df_c.sample(100_000)\n",
    "df_s['commentBody_preprocessed'] = df_s['commentBody'].progress_apply(preprocess)\n",
    "\n",
    "tqdm.pandas(desc=\"Tokenize comment sample\")\n",
    "df_s['tokenized_input_1024'] = df_s['commentBody_preprocessed'].progress_apply(tokenize_text)\n",
    "df_s['num_tokens'] = df_s['tokenized_input_1024'].apply(count_tokens)\n",
    "\n",
    "print(f\"Average number of tokens: {df_s['num_tokens'].mean()}\")\n",
    "print(f\"Median number of tokens:  {df_s['num_tokens'].median()}\")\n",
    "print(f\"Minimum number of tokens: {df_s['num_tokens'].min()}\")\n",
    "print(f\"Maximum number of tokens: {df_s['num_tokens'].max()}\")\n",
    "print(f\"Number of tokens > 512:   {(df_s['num_tokens'] > 512).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ac5b1-f48a-4a49-9834-0e0005693361",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "<a class=\"anchor\" id=\"sentiment\"></a>\n",
    "\n",
    "To reduce calculation times, the model inference is performed on the GPU.  \n",
    "The duration of the sentiment analysis for each comment in the dataset is strongly dependent on the available hardware.  \n",
    "Efforts to parallelize the processing of the CardiffNLP/twitter-xlm-roberta-base-sentiment model were unsuccessful.   \n",
    "Sequentially processing each comment already fully utilizes my GPU (RTX 3060) at 100% capacity, achieving only 60 analyses per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e960a3c3-fa08-4676-bbf1-207e4750eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocess comment sample: 100%|████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 45455.87it/s]\n",
      "Sentiment Analysis: 100%|██████████████████████████████████████████████████████████| 1000/1000 [00:27<00:00, 36.70it/s]\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis(row, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Perform sentiment analysis on a single comment.\n",
    "    \n",
    "    Parameters:\n",
    "    row (str): Preprocessed comment body.\n",
    "    tokenizer: The tokenizer from the pretrained sentiment model.\n",
    "    model: The pre-trained sentiment model.\n",
    "    \n",
    "    Returns:\n",
    "    float: The polarity score.\n",
    "    \"\"\"\n",
    "    preprocessed_text = row\n",
    "    encoded_input = tokenizer(preprocessed_text, return_tensors='pt', truncation=True, max_length=512, padding=True).to('cuda')\n",
    "    model = model.to('cuda')\n",
    "    output = model(**encoded_input)\n",
    "    \n",
    "    scores = output.logits[0].cpu().detach()\n",
    "    scores = softmax(scores)\n",
    "    sentiment_scores = {'positive': scores[2], 'neutral': scores[1], 'negative': scores[0]}\n",
    "\n",
    "    weights = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "    weighted_sum = sum(sentiment_scores[sentiment] * weights[sentiment] for sentiment in sentiment_scores)\n",
    "    polarity_score = np.tanh(weighted_sum)\n",
    "    \n",
    "    return polarity_score\n",
    "\n",
    "tqdm.pandas(desc=\"Preprocess comment sample\")\n",
    "df_c = df_c[df_c['commentBody'].notna()].copy().sample(1000)\n",
    "df_c['commentBody_preprocessed'] = df_c['commentBody'].progress_apply(preprocess)\n",
    "\n",
    "tqdm.pandas(desc=\"Sentiment Analysis\")\n",
    "df_c['polarity_scores'] = df_c['commentBody_preprocessed'].progress_apply(sentiment_analysis, args=(tokenizer, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddbe323-8cda-4a97-9eb0-382ab740eb25",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "<a class=\"anchor\" id=\"saving\"></a>\n",
    "\n",
    "The final results of the fully processed and analyzed dataset will be saved as a parquet file, containing the initial comments table, including a new column 'polarity_scores'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39099075-3f35-4254-a8a3-cd7c0e69b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.read_parquet('sentiments.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94692086-8bbd-47d3-9ee0-8a295450b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
