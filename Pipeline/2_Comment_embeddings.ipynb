{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70173413-6f36-4068-b98c-5c3175335cca",
   "metadata": {},
   "source": [
    "# II Training Doc2Vec Model & Inferring Comment Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6954467-2892-4a0a-acaf-1d85f9691f55",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Loading the Data and Necessary Libraries](#loading-dependencies)\n",
    "2. [Preprocess comments](#Preprocessing)\n",
    "3. [Load or Train Model ](#Gensim-Model)\n",
    "4. [Calculate Vector representations and Save results](#Vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea39fb-ba6f-456e-af76-55a52baff6c2",
   "metadata": {},
   "source": [
    "## Loading Data and Libraries \n",
    "<a class=\"anchor\" id=\"loading-dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4363f1b0-da64-4ec1-a84f-068d3ec4c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import logging\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "df_c = pd.read_parquet('Comments.parquet')\n",
    "df_c = df_c[['commentID','commentBody']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53891ced-6de2-401c-a871-e2dece596058",
   "metadata": {},
   "source": [
    "## Preprocess comments \n",
    "<a class=\"anchor\" id=\"Preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "076bdc10-d7bd-45eb-a4e1-8de1e648d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "    '''\n",
    "    -Converts a comment into tokens using Gensim's simple_preprocess \n",
    "    -Returns a TaggedDocument containing tokens and the row index\n",
    "    '''\n",
    "    index = row.name  \n",
    "    comment = row['commentBody']\n",
    "    tokens = gensim.utils.simple_preprocess(comment)\n",
    "    return gensim.models.doc2vec.TaggedDocument(tokens, [index])\n",
    "\n",
    "df_c['preprocessed_sentences'] = df_c.apply(preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73c5d1-9f7b-4294-a593-4f7fd3e0ea8b",
   "metadata": {},
   "source": [
    "## Load or Train Model \n",
    "<a class=\"anchor\" id=\"Gensim-Model\"></a>\n",
    "\n",
    "The Doc2VEc model is trained on the entire comment corups of the dataset and is being stored as indepredent model File \n",
    "Before training the code check if a model file is alredy present in the directory ready to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a5c5f-656c-4c6e-b6a6-90f89d1e944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = df_c['preprocessed_sentences'].values\n",
    "\n",
    "model_file = \"Doc2vec.model\"\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    print(\"Loading existing model...\")\n",
    "    model = Doc2Vec.load(model_file)\n",
    "else:\n",
    "    print(\"Training new model...\")\n",
    "    model = Doc2Vec(tagged_data, vector_size=100, window=5, min_count=15, workers=8, epochs=20)\n",
    "    model.save(model_file)\n",
    "    print(\"Model saved as\", model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98101bae-002b-4f50-93df-d42d06ccff08",
   "metadata": {},
   "source": [
    "## Calculate Vector representations and Save results\n",
    "<a class=\"anchor\" id=\"Vectors\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d6b37ff-5b99-4370-b8c7-0b3796df4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(comment_clean):\n",
    "    '''\n",
    "    -Infers a vector for the preprocessed comment tokens using the Doc2Vec model.\n",
    "    '''\n",
    "    vector = model.infer_vector(comment_clean[0])\n",
    "    return vector\n",
    "\n",
    "\n",
    "df_c['comment_vector'] = df_c['preprocessed_sentences'].progress_apply(get_vector)\n",
    "df_c = df_c.drop('preprocessed_sentences', axis=1)\n",
    "df_c.to_parquet('Comment_embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b5674-026e-48d4-9203-86b7cf1bc832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
